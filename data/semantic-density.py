#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
semantic_density.py
--------------------
Calcula a densidade semÃ¢ntica (SD) de um texto, template ou prompt.

DefiniÃ§Ã£o:
  SD = 1 - (E[entropia vetorial] / dispersÃ£o mÃ©dia)
onde:
  - alta SD â†’ coerÃªncia e convergÃªncia semÃ¢ntica
  - baixa SD â†’ ruÃ­do e dispersÃ£o semÃ¢ntica

ReferÃªncia conceitual: Estrutura de AtenÃ§Ã£o para InferÃªncia (EIA)
"""

import argparse
import numpy as np
from scipy.spatial.distance import pdist, squareform
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from scipy.stats import entropy

# ============================================================
# ðŸ”¹ FunÃ§Ãµes principais
# ============================================================

def compute_semantic_density(text: str, model_name: str = "sentence-transformers/all-MiniLM-L6-v2"):
    """
    Calcula a densidade semÃ¢ntica de um texto ou prompt.
    Retorna um dicionÃ¡rio com SD, entropia mÃ©dia e dispersÃ£o.
    """
    model = SentenceTransformer(model_name)
    sentences = [s.strip() for s in text.split(".") if len(s.strip()) > 2]
    if len(sentences) < 2:
        raise ValueError("Texto muito curto. ForneÃ§a ao menos duas sentenÃ§as.")

    embeddings = model.encode(sentences, convert_to_tensor=False)
    sim_matrix = cosine_similarity(embeddings)

    # DispersÃ£o mÃ©dia
    distances = pdist(embeddings, metric='cosine')
    mean_dispersion = np.mean(distances)

    # Entropia mÃ©dia
    probs = sim_matrix / np.sum(sim_matrix, axis=1, keepdims=True)
    entropy_vals = [entropy(p) for p in probs]
    mean_entropy = np.mean(entropy_vals)

    # Densidade SemÃ¢ntica (normalizada)
    sd = 1 - (mean_entropy / (mean_dispersion + 1e-8))
    sd = np.clip(sd, 0, 1)

    return {
        "semantic_density": float(sd),
        "mean_entropy": float(mean_entropy),
        "mean_dispersion": float(mean_dispersion),
        "n_sentences": len(sentences)
    }

# ============================================================
# ðŸ”¹ CLI Interface
# ============================================================

def main():
    parser = argparse.ArgumentParser(description="Calcula a densidade semÃ¢ntica (SD) de um texto/prompt.")
    parser.add_argument("input", type=str, help="Texto de entrada ou caminho para arquivo .txt/.md")
    parser.add_argument("--model", type=str, default="sentence-transformers/all-MiniLM-L6-v2",
                        help="Modelo de embeddings (default: all-MiniLM-L6-v2)")
    args = parser.parse_args()

    # Ler conteÃºdo
    try:
        if args.input.endswith(".txt") or args.input.endswith(".md"):
            with open(args.input, "r", encoding="utf-8") as f:
                text = f.read()
        else:
            text = args.input
    except Exception as e:
        print(f"Erro ao ler entrada: {e}")
        return

    result = compute_semantic_density(text, args.model)
    print(f"\nðŸ“Š Semantic Density Analysis\n{'-'*40}")
    print(f"â†’ SD Score:           {result['semantic_density']:.4f}")
    print(f"â†’ Mean Entropy (H):   {result['mean_entropy']:.4f}")
    print(f"â†’ Mean Dispersion:    {result['mean_dispersion']:.4f}")
    print(f"â†’ Sentences analyzed: {result['n_sentences']}\n")


if __name__ == "__main__":
    main()
